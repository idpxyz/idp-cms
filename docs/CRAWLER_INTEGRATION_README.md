# å¤–éƒ¨çˆ¬è™«æ•°æ®å†™å…¥é›†æˆæ–¹æ¡ˆ

## æ¦‚è¿°

æœ¬æ–¹æ¡ˆä¸ºåŸºäºWagtail 7.1çš„CMSç³»ç»Ÿæä¾›äº†å®Œæ•´çš„å¤–éƒ¨çˆ¬è™«æ•°æ®å†™å…¥è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒæ‰¹é‡æ–‡ç« åˆ›å»ºã€æ›´æ–°å’Œå»é‡åŠŸèƒ½ã€‚

## ğŸ¯ è§£å†³çš„é—®é¢˜

- âœ… å¤–éƒ¨çˆ¬è™«ç¨‹åºå¦‚ä½•å®‰å…¨åœ°å‘CMSå†™å…¥æ•°æ®
- âœ… æ‰¹é‡å¤„ç†å¤§é‡æ–‡ç« æ•°æ®
- âœ… é¿å…é‡å¤æ–‡ç« çš„åˆ›å»º
- âœ… æ”¯æŒå¤šç«™ç‚¹æ¶æ„
- âœ… å¤„ç†å¤–éƒ¨æ¥æºå’Œå†…éƒ¨æ¥æºçš„æ–‡ç« 
- âœ… æä¾›å®Œæ•´çš„APIè®¤è¯å’Œæƒé™æ§åˆ¶

## ğŸš€ æ ¸å¿ƒåŠŸèƒ½

### 1. APIç«¯ç‚¹
- `POST /api/crawler/articles/bulk` - æ‰¹é‡åˆ›å»º/æ›´æ–°æ–‡ç« 
- `POST /api/crawler/articles/check-duplicates` - æ£€æŸ¥é‡å¤æ–‡ç« 
- `GET /api/crawler/sites/info` - è·å–ç«™ç‚¹ç»“æ„ä¿¡æ¯

### 2. è®¤è¯æœºåˆ¶
- APIå¯†é’¥è®¤è¯ï¼ˆX-API-Key + X-API-Clientï¼‰
- å®¢æˆ·ç«¯ç™½åå•æ§åˆ¶
- IPåœ°å€é™åˆ¶ï¼ˆå¯é€‰ï¼‰

### 3. æ•°æ®å¤„ç†
- æ”¯æŒHTMLæ ¼å¼çš„æ–‡ç« å†…å®¹
- è‡ªåŠ¨å¤„ç†é¢‘é“ã€åœ°åŒºã€è¯­è¨€å…³è”
- æ™ºèƒ½å»é‡ï¼ˆåŸºäºURLå’Œæ ‡é¢˜ï¼‰
- å¤–éƒ¨ç«™ç‚¹ä¿¡æ¯ç®¡ç†
- æ ‡ç­¾å’Œåˆ†ç±»è‡ªåŠ¨åˆ›å»º

### 4. å®‰å…¨ç‰¹æ€§
- HMACå¯†é’¥éªŒè¯
- æ‰¹é‡æ“ä½œæ•°é‡é™åˆ¶
- è¯¦ç»†çš„æ“ä½œæ—¥å¿—
- è¯•è¿è¡Œæ¨¡å¼æ”¯æŒ

## ğŸ“ æ–‡ä»¶ç»“æ„

```
/opt/idp-cms/
â”œâ”€â”€ apps/api/rest/crawler_api.py        # çˆ¬è™«APIå®ç°
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ urls.py                         # URLè·¯ç”±é…ç½®ï¼ˆå·²æ›´æ–°ï¼‰
â”‚   â””â”€â”€ crawler_api_settings.py        # é…ç½®ç¤ºä¾‹
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ CRAWLER_API_GUIDE.md          # è¯¦ç»†ä½¿ç”¨æŒ‡å—
â”‚   â””â”€â”€ CRAWLER_INTEGRATION_README.md  # æœ¬æ–‡ä»¶
â””â”€â”€ scripts/test_crawler_api.py         # APIæµ‹è¯•è„šæœ¬
```

## âš™ï¸ å¿«é€Ÿé…ç½®

### 1. æ·»åŠ APIå¯†é’¥é…ç½®

åœ¨ `settings.py` ä¸­æ·»åŠ ï¼š

```python
import os

# çˆ¬è™«APIå¯†é’¥
CRAWLER_API_KEYS = {
    'news_crawler': os.getenv('CRAWLER_API_KEY_NEWS', 'your-secret-key-here'),
    'content_bot': os.getenv('CRAWLER_API_KEY_CONTENT', 'another-secret-key'),
}

# å¯é€‰é…ç½®
CRAWLER_API_SETTINGS = {
    'MAX_ARTICLES_PER_BATCH': 100,
    'ALLOW_ARTICLE_UPDATES': True,
    'DETAILED_LOGGING': True,
}
```

### 2. ç¯å¢ƒå˜é‡è®¾ç½®

```bash
# ç”Ÿäº§ç¯å¢ƒ
export CRAWLER_API_KEY_NEWS="your-production-secret-key"
export CRAWLER_API_KEY_CONTENT="another-production-key"

# æµ‹è¯•ç¯å¢ƒ  
export CMS_BASE_URL="https://your-cms.com"
export TEST_SITE_HOSTNAME="your-site.com"
```

### 3. è¿è¡Œæµ‹è¯•

```bash
cd /opt/idp-cms
python scripts/test_crawler_api.py
```

## ğŸ› ï¸ ä½¿ç”¨ç¤ºä¾‹

### Pythonçˆ¬è™«ç¤ºä¾‹

```python
import requests

class NewsSpider:
    def __init__(self):
        self.cms_client = CMSCrawlerClient(
            base_url="https://your-cms.com",
            api_key="your-secret-key",
            client_name="news_crawler"
        )
    
    def crawl_and_upload(self):
        # 1. çˆ¬å–æ–‡ç« æ•°æ®
        articles = self.crawl_news_sites()
        
        # 2. æ£€æŸ¥é‡å¤
        duplicates = self.cms_client.check_duplicates("target-site.com", articles)
        
        # 3. è¿‡æ»¤å·²å­˜åœ¨çš„æ–‡ç« 
        new_articles = [
            article for i, article in enumerate(articles)
            if not duplicates['results'][i]['is_duplicate']
        ]
        
        # 4. æ‰¹é‡ä¸Šä¼ 
        if new_articles:
            result = self.cms_client.bulk_create_articles(
                "target-site.com", new_articles
            )
            print(f"ä¸Šä¼ å®Œæˆ: æ–°å¢{result['summary']['created']}ç¯‡æ–‡ç« ")
```

### Node.jsçˆ¬è™«ç¤ºä¾‹

```javascript
const puppeteer = require('puppeteer');
const { CMSCrawlerClient } = require('./cms-client');

class NewsScraper {
    constructor() {
        this.cms = new CMSCrawlerClient(
            'https://your-cms.com',
            process.env.CRAWLER_API_KEY,
            'js_scraper'
        );
    }
    
    async scrapeAndUpload() {
        const browser = await puppeteer.launch();
        const articles = await this.scrapeArticles(browser);
        
        const result = await this.cms.bulkCreateArticles(
            'target-site.com', 
            articles
        );
        
        console.log(`ä¸Šä¼ ç»“æœ: ${result.summary.created} ç¯‡æ–°æ–‡ç« `);
        await browser.close();
    }
}
```

## ğŸ”§ è¿ç»´è¦ç‚¹

### ç›‘æ§æŒ‡æ ‡
- APIè°ƒç”¨é¢‘ç‡å’ŒæˆåŠŸç‡
- æ–‡ç« åˆ›å»º/æ›´æ–°æ•°é‡
- é‡å¤æ–‡ç« æ£€æµ‹æ•ˆç‡
- é”™è¯¯æ—¥å¿—å’Œå¼‚å¸¸æ¨¡å¼

### æ€§èƒ½ä¼˜åŒ–
- å•æ¬¡æ‰¹é‡æ“ä½œé™åˆ¶åœ¨100ç¯‡æ–‡ç« ä»¥å†…
- ä½¿ç”¨è¯•è¿è¡Œæ¨¡å¼éªŒè¯æ•°æ®
- å®ç°é‡è¯•æœºåˆ¶å¤„ç†ä¸´æ—¶æ•…éšœ
- å®šæœŸæ¸…ç†æµ‹è¯•æ•°æ®

### å®‰å…¨ç»´æŠ¤
- å®šæœŸè½®æ¢APIå¯†é’¥
- ç›‘æ§å¼‚å¸¸è®¿é—®æ¨¡å¼
- å®¡æŸ¥çˆ¬è™«å®¢æˆ·ç«¯æƒé™
- å¤‡ä»½é‡è¦é…ç½®æ–‡ä»¶

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **è®¤è¯å¤±è´¥**
   - æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®é…ç½®
   - ç¡®è®¤å®¢æˆ·ç«¯åç§°åŒ¹é…
   - éªŒè¯è¯·æ±‚å¤´æ ¼å¼

2. **ç«™ç‚¹ä¸å­˜åœ¨**
   - ç¡®è®¤ç«™ç‚¹åŸŸåæ­£ç¡®
   - æ£€æŸ¥Wagtailç«™ç‚¹é…ç½®
   - éªŒè¯å¤šç«™ç‚¹è®¾ç½®

3. **æ–‡ç« åˆ›å»ºå¤±è´¥**
   - æ£€æŸ¥å¿…éœ€å­—æ®µæ˜¯å¦å®Œæ•´
   - éªŒè¯HTMLå†…å®¹æ ¼å¼
   - ç¡®è®¤é¢‘é“å’Œåœ°åŒºé…ç½®

4. **æƒé™é—®é¢˜**
   - æ£€æŸ¥APIå®¢æˆ·ç«¯æƒé™è®¾ç½®
   - éªŒè¯IPç™½åå•é…ç½®
   - ç¡®è®¤æ•°æ®åº“å†™å…¥æƒé™

### æ—¥å¿—æŸ¥çœ‹

```bash
# æŸ¥çœ‹APIæ“ä½œæ—¥å¿—
tail -f /opt/idp-cms/logs/crawler_api.log

# æŸ¥çœ‹Djangoåº”ç”¨æ—¥å¿—
tail -f /opt/idp-cms/logs/django.log

# æŸ¥çœ‹Nginxè®¿é—®æ—¥å¿—ï¼ˆå¦‚é€‚ç”¨ï¼‰
tail -f /var/log/nginx/access.log | grep crawler
```

## ğŸ“ ä¸‹ä¸€æ­¥æ”¹è¿›

- [ ] æ”¯æŒå›¾ç‰‡è‡ªåŠ¨ä¸‹è½½å’Œå¤„ç†
- [ ] å®ç°å¢é‡æ›´æ–°æœºåˆ¶
- [ ] æ·»åŠ æ–‡ç« è´¨é‡è¯„åˆ†
- [ ] æ”¯æŒWebhooké€šçŸ¥
- [ ] å®ç°GraphQL API
- [ ] æ·»åŠ æ•°æ®ç»Ÿè®¡é¢æ¿

## ğŸ¤ æŠ€æœ¯æ”¯æŒ

å¦‚éœ€å¸®åŠ©ï¼Œè¯·å‚è€ƒï¼š
- è¯¦ç»†APIæ–‡æ¡£: [CRAWLER_API_GUIDE.md](CRAWLER_API_GUIDE.md)
- æµ‹è¯•è„šæœ¬: [test_crawler_api.py](../scripts/test_crawler_api.py)
- é…ç½®ç¤ºä¾‹: [crawler_api_settings.py](../config/crawler_api_settings.py)

---

**ç‰ˆæœ¬**: v1.0  
**æ›´æ–°æ—¶é—´**: 2024å¹´9æœˆ  
**å…¼å®¹æ€§**: Wagtail 7.1+, Django 4.2+
