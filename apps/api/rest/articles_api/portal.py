"""
é—¨æˆ·èšåˆAPIç«¯ç‚¹

åŒ…å«é—¨æˆ·èšåˆæ–‡ç« åŠŸèƒ½
"""

from rest_framework.decorators import api_view
from rest_framework.response import Response
from rest_framework import status

from apps.core.site_utils import get_site_from_request
from apps.searchapp.client import get_client
from apps.searchapp.simple_index import get_index_name
from ..utils import apply_field_filtering, generate_etag
from ...utils.rate_limit import PORTAL_ARTICLES_RATE_LIMIT


@api_view(["GET"])
@PORTAL_ARTICLES_RATE_LIMIT
def portal_articles(request):
    """
    é—¨æˆ·èšåˆæ–‡ç« æ¥å£
    
    åªè¿”å›æ‘˜è¦ï¼Œä¸è¿”å›æ­£æ–‡ï¼Œç”¨äºé—¨æˆ·èšåˆå±•ç¤º
    æ”¯æŒå‚æ•°ï¼š
    - allow_aggregate: æ˜¯å¦å…è®¸èšåˆï¼ˆé»˜è®¤trueï¼‰
    - fields: å­—æ®µç™½åå•é€‰æ‹©
    - channel: é¢‘é“è¿‡æ»¤
    - region: åœ°åŒºè¿‡æ»¤
    - q: æœç´¢å…³é”®è¯
    - is_featured: æ˜¯å¦ç½®é¡¶
    - since: æ—¶é—´è¿‡æ»¤
    - order: æ’åº
    - page: åˆ†é¡µ
    - size: æ¯é¡µå¤§å°
    """
    try:
        # 1. å‚æ•°
        allow_aggregate = request.query_params.get("allow_aggregate", "true").lower() == "true"
        fields = request.query_params.get("fields", "").split(",") if request.query_params.get("fields") else []
        channel = request.query_params.get("channel")
        categories = request.query_params.get("categories")  # é€—å·åˆ†éš”
        page = max(1, int(request.query_params.get("page", 1)))
        size = min(int(request.query_params.get("size", 20)), 100)
        start_from = (page - 1) * size

        # 2. ç«™ç‚¹ä¸ç´¢å¼•
        site = get_site_from_request(request)
        client = get_client()
        index = get_index_name(site)

        # 3. OpenSearch æŸ¥è¯¢æ„å»º
        must = []
        if channel:
            must.append({"term": {"primary_channel_slug": channel}})
        if categories:
            cats = [c.strip() for c in categories.split(',') if c.strip()]
            if cats:
                must.append({"terms": {"categories": cats}})
        body = {
            "query": {"bool": {"must": must or [{"match_all": {}}]}},
            "sort": [{"first_published_at": {"order": "desc"}}, {"article_id": {"order": "desc"}}],
            "from": start_from,
            "size": size,
            "track_total_hits": True,
        }

        # 4. æ‰§è¡ŒæŸ¥è¯¢
        res = client.search(index=index, body=body)
        hits = res.get("hits", {})
        total = hits.get("total", {}).get("value", 0)

        # 5. åºåˆ—åŒ–ï¼ˆä¼˜åŒ–ï¼šæŒ‰ slug æ‰¹é‡è¡¥é½å°é¢å›¾ï¼Œé¿å… id ä¸ä¸€è‡´é—®é¢˜ï¼‰
        # å…ˆæ”¶é›†éœ€è¦è¡¥å……å°é¢çš„ slug
        slugs_need_cover = []
        for h in hits.get("hits", []):
            s = h.get("_source", {})
            if not (s.get("cover_url") or s.get("image_url")) and s.get("slug"):
                slugs_need_cover.append(s.get("slug"))

        # æ‰¹é‡æŸ¥è¯¢æ•°æ®åº“ï¼šä¼˜å…ˆä½¿ç”¨å°é¢å¤–é”®ï¼Œå…¶æ¬¡ä»æ­£æ–‡æå–é¦–å›¾
        from apps.news.models import ArticlePage
        from wagtail.images import get_image_model
        import re
        slug_to_cover = {}
        if slugs_need_cover:
            qs = ArticlePage.objects.filter(slug__in=slugs_need_cover).select_related("cover").values("slug", "body", "cover_id")

            # æ‰¹é‡å–å°é¢æ–‡ä»¶ URL
            Image = get_image_model()
            cover_ids = [row["cover_id"] for row in qs if row.get("cover_id")]
            id_to_url = {}
            if cover_ids:
                for img in Image.objects.filter(id__in=cover_ids).only("id", "file"):
                    try:
                        id_to_url[img.id] = img.file.url
                    except Exception:
                        pass

            # æ„å»º slug -> cover_url æ˜ å°„
            for row in qs:
                url = id_to_url.get(row.get("cover_id"), "")
                if not url:
                    body_html = str(row.get("body") or "")
                    m = re.search(r'<img[^>]*src=["\']([^"\']+)["\']', body_html, re.I)
                    if m:
                        url = m.group(1)
                if url:
                    slug_to_cover[row["slug"]] = url
        
        # åºåˆ—åŒ–ç»“æœ
        items = []
        for h in hits.get("hits", []):
            s = h.get("_source", {})
            
            # æå–å°é¢å›¾ï¼šä¼˜å…ˆ OpenSearchï¼Œå…¶æ¬¡ä»æ•°æ®åº“æ­£æ–‡æå–
            cover_url = s.get("cover_url") or s.get("image_url") or ""
            if not cover_url:
                cover_url = slug_to_cover.get(s.get("slug", ""), "")
            # æœ€ç»ˆå…œåº•ï¼šè¿”å›ç«™ç‚¹å†…é»˜è®¤å°é¢ï¼Œé¿å…å‰ç«¯æ˜¾ç¤ºå ä½ç¬¦
            if not cover_url:
                cover_url = "/images/default-covers/default.svg"
            
            item = {
                "id": s.get("article_id") or h.get("_id"),
                "title": s.get("title"),
                "slug": s.get("slug"),
                "excerpt": s.get("summary") or "",
                "cover_url": cover_url,  # ğŸš€ ä» OpenSearch æ•°æ®æˆ–æ­£æ–‡ä¸­æå–
                "publish_at": s.get("first_published_at") or s.get("publish_time"),
                "channel_slug": s.get("primary_channel_slug") or s.get("channel"),
                "region": s.get("region"),
                "source_site": site,
                "source_url": s.get("url") or "",
                "canonical_url": s.get("url") or "",
            }
            if fields:
                item = apply_field_filtering(item, fields)
            items.append(item)

        # 6. å“åº”
        response_data = {
            "items": items,
            "pagination": {
                "page": page,
                "size": size,
                "total": total,
                "has_next": (page * size) < total,
                "has_prev": page > 1,
            },
            "meta": {"type": "portal_aggregation", "allow_aggregate": allow_aggregate, "site": site},
        }

        response = Response(response_data)
        response["Cache-Control"] = "public, s-maxage=120, stale-while-revalidate=60"
        etag = generate_etag(response_data)
        response["ETag"] = f'"{etag}"'
        response["Surrogate-Key"] = "portal:aggregation articles:all"
        return response

    except Exception as e:
        return Response({"error": f"Internal server error: {str(e)}"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
