#!/usr/bin/env python3
"""
æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å™¨ - éªŒè¯Wagtailä¸OpenSearchä¹‹é—´çš„æ•°æ®ä¸€è‡´æ€§

ç”¨æ³•ï¼š
  python manage.py check_data_consistency
  python manage.py check_data_consistency --site=aivoya.com
  python manage.py check_data_consistency --fix-auto
"""

from django.core.management.base import BaseCommand
from django.db import connection
from wagtail.models import Site
from apps.news.models import ArticlePage
from apps.searchapp.client import get_client
from apps.searchapp.alias import read_alias
from apps.core.site_utils import normalize_site_identifier
import json


class Command(BaseCommand):
    help = "æ£€æŸ¥å’ŒéªŒè¯Wagtailä¸OpenSearchä¹‹é—´çš„æ•°æ®ä¸€è‡´æ€§"

    def add_arguments(self, parser):
        parser.add_argument(
            '--site',
            type=str,
            help='æ£€æŸ¥ç‰¹å®šç«™ç‚¹çš„æ•°æ®ä¸€è‡´æ€§',
        )
        parser.add_argument(
            '--fix-auto',
            action='store_true',
            help='è‡ªåŠ¨ä¿®å¤å‘ç°çš„æ•°æ®ä¸ä¸€è‡´é—®é¢˜',
        )
        parser.add_argument(
            '--verbose',
            action='store_true',
            help='æ˜¾ç¤ºè¯¦ç»†çš„æ£€æŸ¥ä¿¡æ¯',
        )

    def handle(self, *args, **options):
        self.verbose = options['verbose']
        self.fix_auto = options['fix_auto']
        target_site = options.get('site')

        self.stdout.write("ğŸ” å¼€å§‹æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥...")
        
        # æ£€æŸ¥Wagtailç«™ç‚¹é…ç½®
        site_issues = self.check_wagtail_sites()
        
        # æ£€æŸ¥ç«™ç‚¹æ•°æ®å¯¹åº”å…³ç³»
        if target_site:
            consistency_issues = self.check_site_consistency(target_site)
        else:
            consistency_issues = self.check_all_sites_consistency()
        
        # æ£€æŸ¥OpenSearchç´¢å¼•çŠ¶æ€
        index_issues = self.check_opensearch_indices()
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report(site_issues, consistency_issues, index_issues)
        
        if self.fix_auto:
            self.auto_fix_issues(site_issues, consistency_issues, index_issues)

    def check_wagtail_sites(self):
        """æ£€æŸ¥Wagtailç«™ç‚¹é…ç½®é—®é¢˜"""
        self.stdout.write("\n=== Wagtailç«™ç‚¹é…ç½®æ£€æŸ¥ ===")
        
        issues = []
        sites = Site.objects.all()
        
        # æ£€æŸ¥ç«™ç‚¹æ ¹é¡µé¢é‡å¤
        root_pages = {}
        for site in sites:
            root_id = site.root_page_id
            if root_id in root_pages:
                issue = {
                    'type': 'duplicate_root_page',
                    'severity': 'high',
                    'message': f'ç«™ç‚¹ {site.hostname} ä¸ {root_pages[root_id]} å…±äº«æ ¹é¡µé¢ {root_id}',
                    'sites': [site.hostname, root_pages[root_id]],
                    'root_page_id': root_id
                }
                issues.append(issue)
                self.stdout.write(self.style.ERROR(f"âŒ {issue['message']}"))
            else:
                root_pages[root_id] = site.hostname
                if self.verbose:
                    self.stdout.write(f"âœ… ç«™ç‚¹ {site.hostname} æ ¹é¡µé¢ {root_id} æ­£å¸¸")
        
        # æ£€æŸ¥ç«™ç‚¹æ•°æ®åˆ†å¸ƒ
        for site in sites:
            article_count = ArticlePage.objects.live().descendant_of(site.root_page).count()
            if self.verbose:
                self.stdout.write(f"ğŸ“Š ç«™ç‚¹ {site.hostname}: {article_count} ç¯‡æ–‡ç« ")
            
            if article_count == 0 and site.hostname != 'localhost':
                issue = {
                    'type': 'empty_site',
                    'severity': 'medium',
                    'message': f'ç«™ç‚¹ {site.hostname} æ²¡æœ‰æ–‡ç« å†…å®¹',
                    'site': site.hostname,
                    'article_count': 0
                }
                issues.append(issue)
                self.stdout.write(self.style.WARNING(f"âš ï¸  {issue['message']}"))
        
        return issues

    def check_site_consistency(self, site_identifier):
        """æ£€æŸ¥ç‰¹å®šç«™ç‚¹çš„æ•°æ®ä¸€è‡´æ€§"""
        self.stdout.write(f"\n=== ç«™ç‚¹ {site_identifier} æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ ===")
        
        issues = []
        
        try:
            # è·å–Wagtailæ•°æ®
            wagtail_data = self.get_wagtail_site_data(site_identifier)
            
            # è·å–OpenSearchæ•°æ®
            opensearch_data = self.get_opensearch_site_data(site_identifier)
            
            # æ¯”è¾ƒæ•°æ®ä¸€è‡´æ€§
            consistency_check = self.compare_site_data(
                site_identifier, wagtail_data, opensearch_data
            )
            issues.extend(consistency_check)
            
        except Exception as e:
            issue = {
                'type': 'check_error',
                'severity': 'high',
                'message': f'æ£€æŸ¥ç«™ç‚¹ {site_identifier} æ—¶å‡ºé”™: {str(e)}',
                'site': site_identifier,
                'error': str(e)
            }
            issues.append(issue)
            self.stdout.write(self.style.ERROR(f"âŒ {issue['message']}"))
        
        return issues

    def check_all_sites_consistency(self):
        """æ£€æŸ¥æ‰€æœ‰ç«™ç‚¹çš„æ•°æ®ä¸€è‡´æ€§"""
        self.stdout.write("\n=== å…¨ç«™æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ ===")
        
        all_issues = []
        sites = Site.objects.all()
        
        for site in sites:
            site_issues = self.check_site_consistency(site.hostname)
            all_issues.extend(site_issues)
        
        return all_issues

    def get_wagtail_site_data(self, site_identifier):
        """è·å–Wagtailä¸­çš„ç«™ç‚¹æ•°æ®"""
        try:
            site = Site.objects.get(hostname=site_identifier)
            articles = ArticlePage.objects.live().descendant_of(site.root_page)
            
            return {
                'site_id': site.id,
                'hostname': site.hostname,
                'root_page_id': site.root_page_id,
                'article_count': articles.count(),
                'articles': [
                    {
                        'id': article.id,
                        'title': article.title,
                        'publish_time': article.first_published_at.isoformat() if article.first_published_at else None
                    }
                    for article in articles[:10]  # åªå–å‰10ä¸ªä½œä¸ºæ ·æœ¬
                ]
            }
        except Site.DoesNotExist:
            return None

    def get_opensearch_site_data(self, site_identifier):
        """è·å–OpenSearchä¸­çš„ç«™ç‚¹æ•°æ®"""
        try:
            client = get_client()
            normalized_site = normalize_site_identifier(site_identifier)
            index = read_alias(normalized_site)
            
            # æŸ¥è¯¢ç«™ç‚¹æ•°æ®
            query = {
                "query": {"term": {"site": site_identifier}},
                "size": 0,  # åªè¦ç»Ÿè®¡ä¿¡æ¯
                "aggs": {
                    "total_articles": {"value_count": {"field": "article_id"}},
                    "sample_articles": {
                        "top_hits": {
                            "size": 10,
                            "_source": ["article_id", "title", "publish_time", "site"]
                        }
                    }
                }
            }
            
            result = client.search(index=index, body=query)
            total_count = result['hits']['total']['value']
            sample_articles = []
            
            if 'aggregations' in result and 'sample_articles' in result['aggregations']:
                hits = result['aggregations']['sample_articles']['hits']['hits']
                sample_articles = [
                    {
                        'id': hit['_source']['article_id'],
                        'title': hit['_source']['title'],
                        'site': hit['_source']['site'],
                        'publish_time': hit['_source'].get('publish_time')
                    }
                    for hit in hits
                ]
            
            return {
                'index': index,
                'site_identifier': site_identifier,
                'normalized_site': normalized_site,
                'article_count': total_count,
                'articles': sample_articles
            }
            
        except Exception as e:
            return {'error': str(e)}

    def compare_site_data(self, site_identifier, wagtail_data, opensearch_data):
        """æ¯”è¾ƒWagtailå’ŒOpenSearchçš„ç«™ç‚¹æ•°æ®"""
        issues = []
        
        if not wagtail_data:
            issue = {
                'type': 'wagtail_site_missing',
                'severity': 'high',
                'message': f'Wagtailä¸­æœªæ‰¾åˆ°ç«™ç‚¹ {site_identifier}',
                'site': site_identifier
            }
            issues.append(issue)
            self.stdout.write(self.style.ERROR(f"âŒ {issue['message']}"))
            return issues
        
        if 'error' in opensearch_data:
            issue = {
                'type': 'opensearch_error',
                'severity': 'high',
                'message': f'OpenSearchæŸ¥è¯¢ç«™ç‚¹ {site_identifier} å‡ºé”™: {opensearch_data["error"]}',
                'site': site_identifier,
                'error': opensearch_data['error']
            }
            issues.append(issue)
            self.stdout.write(self.style.ERROR(f"âŒ {issue['message']}"))
            return issues
        
        # æ¯”è¾ƒæ–‡ç« æ•°é‡
        wagtail_count = wagtail_data['article_count']
        opensearch_count = opensearch_data['article_count']
        
        if wagtail_count != opensearch_count:
            issue = {
                'type': 'article_count_mismatch',
                'severity': 'medium',
                'message': f'ç«™ç‚¹ {site_identifier} æ–‡ç« æ•°é‡ä¸åŒ¹é…: Wagtail({wagtail_count}) vs OpenSearch({opensearch_count})',
                'site': site_identifier,
                'wagtail_count': wagtail_count,
                'opensearch_count': opensearch_count
            }
            issues.append(issue)
            self.stdout.write(self.style.WARNING(f"âš ï¸  {issue['message']}"))
        else:
            self.stdout.write(f"âœ… ç«™ç‚¹ {site_identifier} æ–‡ç« æ•°é‡ä¸€è‡´: {wagtail_count}")
        
        # æ£€æŸ¥ç«™ç‚¹æ ‡è¯†ç¬¦ä¸€è‡´æ€§
        opensearch_sites = set()
        for article in opensearch_data.get('articles', []):
            opensearch_sites.add(article.get('site'))
        
        if opensearch_sites and site_identifier not in opensearch_sites:
            issue = {
                'type': 'site_identifier_mismatch',
                'severity': 'high',
                'message': f'OpenSearchä¸­ç«™ç‚¹æ ‡è¯†ç¬¦ä¸åŒ¹é…: æœŸæœ› {site_identifier}, å®é™… {opensearch_sites}',
                'site': site_identifier,
                'expected': site_identifier,
                'actual': list(opensearch_sites)
            }
            issues.append(issue)
            self.stdout.write(self.style.ERROR(f"âŒ {issue['message']}"))
        
        return issues

    def check_opensearch_indices(self):
        """æ£€æŸ¥OpenSearchç´¢å¼•çŠ¶æ€"""
        self.stdout.write("\n=== OpenSearchç´¢å¼•çŠ¶æ€æ£€æŸ¥ ===")
        
        issues = []
        
        try:
            client = get_client()
            
            # è·å–æ‰€æœ‰ç´¢å¼•
            indices = client.cat.indices(format='json')
            news_indices = [idx for idx in indices if 'news_' in idx['index']]
            
            if self.verbose:
                self.stdout.write(f"ğŸ“Š æ‰¾åˆ° {len(news_indices)} ä¸ªæ–°é—»ç´¢å¼•:")
                for idx in news_indices:
                    self.stdout.write(f"  - {idx['index']}: {idx['docs.count']} æ–‡æ¡£")
            
            # æ£€æŸ¥ç´¢å¼•å¥åº·çŠ¶æ€
            for idx in news_indices:
                if idx['health'] != 'green':
                    issue = {
                        'type': 'index_health',
                        'severity': 'medium' if idx['health'] == 'yellow' else 'high',
                        'message': f'ç´¢å¼• {idx["index"]} å¥åº·çŠ¶æ€: {idx["health"]}',
                        'index': idx['index'],
                        'health': idx['health']
                    }
                    issues.append(issue)
                    self.stdout.write(self.style.WARNING(f"âš ï¸  {issue['message']}"))
                else:
                    if self.verbose:
                        self.stdout.write(f"âœ… ç´¢å¼• {idx['index']} å¥åº·çŠ¶æ€æ­£å¸¸")
            
        except Exception as e:
            issue = {
                'type': 'opensearch_connection_error',
                'severity': 'high',
                'message': f'è¿æ¥OpenSearchå¤±è´¥: {str(e)}',
                'error': str(e)
            }
            issues.append(issue)
            self.stdout.write(self.style.ERROR(f"âŒ {issue['message']}"))
        
        return issues

    def generate_report(self, site_issues, consistency_issues, index_issues):
        """ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š"""
        self.stdout.write("\n" + "="*60)
        self.stdout.write("ğŸ“‹ æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥æŠ¥å‘Š")
        self.stdout.write("="*60)
        
        all_issues = site_issues + consistency_issues + index_issues
        
        if not all_issues:
            self.stdout.write(self.style.SUCCESS("ğŸ‰ æœªå‘ç°æ•°æ®ä¸€è‡´æ€§é—®é¢˜ï¼"))
            return
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç±»
        high_issues = [i for i in all_issues if i['severity'] == 'high']
        medium_issues = [i for i in all_issues if i['severity'] == 'medium']
        low_issues = [i for i in all_issues if i['severity'] == 'low']
        
        self.stdout.write(f"ğŸ” æ€»è®¡å‘ç° {len(all_issues)} ä¸ªé—®é¢˜:")
        self.stdout.write(f"  ğŸ”´ ä¸¥é‡: {len(high_issues)}")
        self.stdout.write(f"  ğŸŸ¡ ä¸­ç­‰: {len(medium_issues)}")
        self.stdout.write(f"  ğŸŸ¢ è½»å¾®: {len(low_issues)}")
        
        # è¯¦ç»†é—®é¢˜åˆ—è¡¨
        if high_issues:
            self.stdout.write("\nğŸ”´ ä¸¥é‡é—®é¢˜:")
            for issue in high_issues:
                self.stdout.write(f"  - {issue['message']}")
        
        if medium_issues:
            self.stdout.write("\nğŸŸ¡ ä¸­ç­‰é—®é¢˜:")
            for issue in medium_issues:
                self.stdout.write(f"  - {issue['message']}")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_data = {
            'timestamp': self.get_timestamp(),
            'summary': {
                'total_issues': len(all_issues),
                'high_severity': len(high_issues),
                'medium_severity': len(medium_issues),
                'low_severity': len(low_issues)
            },
            'issues': all_issues
        }
        
        report_file = 'data_consistency_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        self.stdout.write(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

    def auto_fix_issues(self, site_issues, consistency_issues, index_issues):
        """è‡ªåŠ¨ä¿®å¤å¯ä¿®å¤çš„é—®é¢˜"""
        self.stdout.write("\nğŸ”§ å¼€å§‹è‡ªåŠ¨ä¿®å¤...")
        
        # è¿™é‡Œå¯ä»¥å®ç°è‡ªåŠ¨ä¿®å¤é€»è¾‘
        # ç›®å‰åªæ˜¯æ¡†æ¶ï¼Œå…·ä½“ä¿®å¤é€»è¾‘æ ¹æ®éœ€è¦å®ç°
        self.stdout.write("âš ï¸  è‡ªåŠ¨ä¿®å¤åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...")

    def get_timestamp(self):
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().isoformat()
