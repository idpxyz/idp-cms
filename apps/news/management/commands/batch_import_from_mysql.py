"""
ç›´æ¥ä»MySQLåˆ†æ‰¹å¯¼å…¥æ–‡ç« 
é¿å…TSVæ ¼å¼é—®é¢˜ï¼Œç›´æ¥åœ¨å†…å­˜ä¸­å¤„ç†

ä½¿ç”¨æ–¹æ³•ï¼š
    python manage.py batch_import_from_mysql --batch-size=1000
"""

from django.core.management.base import BaseCommand
from django.core.management import call_command
import pymysql
import json
import tempfile
import os
import time
from pathlib import Path

class Command(BaseCommand):
    help = 'ç›´æ¥ä»MySQLåˆ†æ‰¹å¯¼å…¥æ–‡ç« ï¼ˆé¿å…æ–‡ä»¶æ ¼å¼é—®é¢˜ï¼‰'

    def add_arguments(self, parser):
        parser.add_argument(
            '--mysql-host',
            type=str,
            default='121.41.73.49',
            help='MySQLä¸»æœº'
        )
        parser.add_argument(
            '--mysql-user',
            type=str,
            default='jrhb',
            help='MySQLç”¨æˆ·å'
        )
        parser.add_argument(
            '--mysql-password',
            type=str,
            default='6VSPmPbuFGnZO1%C',
            help='MySQLå¯†ç '
        )
        parser.add_argument(
            '--mysql-database',
            type=str,
            default='jrhb',
            help='MySQLæ•°æ®åº“'
        )
        parser.add_argument(
            '--batch-size',
            type=int,
            default=1000,
            help='æ¯æ‰¹å¤„ç†æ•°é‡'
        )
        parser.add_argument(
            '--import-batch-size',
            type=int,
            default=500,
            help='å¯¼å…¥å‘½ä»¤çš„batch-size'
        )
        parser.add_argument(
            '--start-from',
            type=int,
            default=0,
            help='ä»ç¬¬Nç¯‡å¼€å§‹'
        )
        parser.add_argument(
            '--limit',
            type=int,
            help='é™åˆ¶æ€»æ•°'
        )
        parser.add_argument(
            '--skip-inline-images',
            action='store_true',
            help='è·³è¿‡æ­£æ–‡å›¾ç‰‡'
        )

    def handle(self, *args, **options):
        start_time = time.time()
        
        self.stdout.write('=' * 80)
        self.stdout.write(self.style.SUCCESS('ğŸ“¦ å¼€å§‹åˆ†æ‰¹å¯¼å…¥'))
        self.stdout.write('=' * 80)
        self.stdout.write('')
        
        # è¿æ¥MySQL
        self.stdout.write('è¿æ¥MySQL...')
        try:
            conn = pymysql.connect(
                host=options['mysql_host'],
                port=3306,
                user=options['mysql_user'],
                password=options['mysql_password'],
                database=options['mysql_database'],
                charset='utf8mb4'
            )
            self.stdout.write(self.style.SUCCESS('âœ“ MySQLè¿æ¥æˆåŠŸ'))
        except Exception as e:
            self.stdout.write(self.style.ERROR(f'âœ— è¿æ¥å¤±è´¥: {e}'))
            return
        
        cursor = conn.cursor(pymysql.cursors.DictCursor)
        
        # æŸ¥è¯¢æ€»æ•°
        cursor.execute("SELECT COUNT(*) as total FROM article WHERE status = 1")
        total = cursor.fetchone()['total']
        self.stdout.write(f'æ€»æ–‡ç« æ•°: {total}')
        self.stdout.write('')
        
        # ç¡®å®šèŒƒå›´
        start = options['start_from']
        limit = options.get('limit') or total
        end = min(start + limit, total)
        batch_size = options['batch_size']
        
        # ç»Ÿè®¡
        stats = {
            'total_processed': 0,
            'total_success': 0,
            'total_failed': 0,
            'batches': 0
        }
        
        # åˆ†æ‰¹å¤„ç†
        current_offset = start
        while current_offset < end:
            batch_limit = min(batch_size, end - current_offset)
            stats['batches'] += 1
            
            self.stdout.write(f'ğŸ“¦ æ‰¹æ¬¡ {stats["batches"]} | Offset: {current_offset} | Size: {batch_limit}')
            
            # æŸ¥è¯¢ä¸€æ‰¹æ•°æ®
            sql = """
                SELECT 
                    a.id, a.title, a.cate_id, a.img, a.add_time, a.last_time,
                    a.author, a.tags, a.status, a.fromurl, a.seo_title,
                    a.seo_desc, a.seo_keys, i.info
                FROM article a
                LEFT JOIN article_info i ON a.id = i.article_id
                WHERE a.status = 1
                ORDER BY a.add_time DESC
                LIMIT %s OFFSET %s
            """
            
            try:
                cursor.execute(sql, (batch_limit, current_offset))
                articles = cursor.fetchall()
                
                if not articles:
                    break
                
                # å¤„ç†æ—¶é—´æˆ³
                for article in articles:
                    if article['add_time']:
                        article['add_time'] = int(article['add_time'])
                    if article['last_time']:
                        article['last_time'] = int(article['last_time'])
                
                # ä¿å­˜åˆ°ä¸´æ—¶JSONæ–‡ä»¶
                temp_file = None
                try:
                    with tempfile.NamedTemporaryFile(
                        mode='w',
                        suffix='.json',
                        delete=False,
                        encoding='utf-8'
                    ) as f:
                        json.dump(articles, f, ensure_ascii=False, indent=2)
                        temp_file = f.name
                    
                    # è°ƒç”¨å¯¼å…¥å‘½ä»¤
                    import_options = {
                        'file': temp_file,
                        'batch_size': options['import_batch_size'],
                        'skip_inline_images': options.get('skip_inline_images', False),
                        'old_site_url': 'http://www.hubeitoday.com.cn',
                        'old_media_path': '/data/webapp/www/file.hubeitoday.com.cn/public',
                        'force_download': False,
                    }
                    
                    call_command('import_old_articles', **import_options)
                    
                    stats['total_success'] += len(articles)
                    self.stdout.write(self.style.SUCCESS(
                        f'âœ“ æ‰¹æ¬¡å®Œæˆ: {len(articles)} ç¯‡'
                    ))
                    
                except Exception as e:
                    stats['total_failed'] += len(articles)
                    self.stdout.write(self.style.ERROR(f'âœ— æ‰¹æ¬¡å¤±è´¥: {e}'))
                
                finally:
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if temp_file and os.path.exists(temp_file):
                        os.unlink(temp_file)
                
                stats['total_processed'] += len(articles)
                current_offset += batch_limit
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (stats['total_processed'] / (end - start)) * 100
                elapsed = time.time() - start_time
                avg_speed = stats['total_processed'] / elapsed if elapsed > 0 else 0
                remaining = (end - start - stats['total_processed']) / avg_speed if avg_speed > 0 else 0
                
                self.stdout.write(
                    f'è¿›åº¦: {stats["total_processed"]}/{end-start} '
                    f'({progress:.1f}%) | '
                    f'é€Ÿåº¦: {avg_speed:.1f} ç¯‡/ç§’ | '
                    f'å‰©ä½™: {remaining/3600:.1f} å°æ—¶'
                )
                self.stdout.write('')
                
            except Exception as e:
                self.stdout.write(self.style.ERROR(f'æ‰¹æ¬¡æŸ¥è¯¢å¤±è´¥: {e}'))
                break
        
        cursor.close()
        conn.close()
        
        # æ€»ç»“
        elapsed = time.time() - start_time
        self.stdout.write('')
        self.stdout.write('=' * 80)
        self.stdout.write(self.style.SUCCESS('âœ… å¯¼å…¥å®Œæˆ'))
        self.stdout.write('=' * 80)
        self.stdout.write(f'æ€»ç”¨æ—¶: {elapsed/3600:.2f} å°æ—¶')
        self.stdout.write(f'æ€»æ‰¹æ¬¡: {stats["batches"]}')
        self.stdout.write(f'æˆåŠŸ: {stats["total_success"]} ç¯‡')
        self.stdout.write(f'å¤±è´¥: {stats["total_failed"]} ç¯‡')
        self.stdout.write(f'å¹³å‡é€Ÿåº¦: {stats["total_processed"]/elapsed:.1f} ç¯‡/ç§’')
        self.stdout.write('=' * 80)

