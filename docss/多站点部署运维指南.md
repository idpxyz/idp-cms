# 多站点部署运维指南

## 概述

本文档介绍多站点架构的部署流程、运维最佳实践、监控策略和故障处理方案。涵盖从开发环境到生产环境的完整部署链路。

## 目录

- [环境准备](#环境准备)
- [部署架构](#部署架构)
- [配置管理](#配置管理)
- [自动化部署](#自动化部署)
- [监控告警](#监控告警)
- [备份恢复](#备份恢复)
- [性能优化](#性能优化)
- [故障处理](#故障处理)
- [扩容方案](#扩容方案)

## 环境准备

### 系统要求

#### 最小配置
- **CPU**: 4 核心
- **内存**: 8GB RAM
- **存储**: 100GB SSD
- **网络**: 100Mbps

#### 推荐配置
- **CPU**: 8 核心
- **内存**: 16GB RAM  
- **存储**: 500GB SSD
- **网络**: 1Gbps

#### 生产配置
- **CPU**: 16+ 核心
- **内存**: 32GB+ RAM
- **存储**: 1TB+ NVMe SSD
- **网络**: 10Gbps

### 依赖服务

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  # 应用服务
  authoring:
    image: idp-cms/authoring:latest
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
    environment:
      - DJANGO_SETTINGS_MODULE=authoring.settings.production
      - MULTI_SITE_ENABLED=true
      
  # 前端服务
  portal:
    image: idp-cms/portal:latest
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 2G
          
  # 数据库服务
  postgres:
    image: postgres:15
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
    volumes:
      - postgres_data:/var/lib/postgresql/data
      
  # 搜索引擎
  opensearch:
    image: opensearchproject/opensearch:2.11.0
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
    environment:
      - cluster.name=multi-site-cluster
      - node.name=opensearch-node
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms4g -Xmx4g"
      
  # 分析数据库
  clickhouse:
    image: clickhouse/clickhouse-server:latest
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
          
  # 缓存和消息队列
  redis:
    image: redis:7-alpine
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
          
  # 负载均衡
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
```

## 部署架构

### 单节点部署

```mermaid
graph TB
    User[用户] --> LB[Nginx 负载均衡]
    LB --> App1[Django App 1]
    LB --> App2[Django App 2]
    LB --> App3[Django App 3]
    
    App1 --> DB[(PostgreSQL)]
    App2 --> DB
    App3 --> DB
    
    App1 --> OS[(OpenSearch)]
    App2 --> OS
    App3 --> OS
    
    App1 --> CH[(ClickHouse)]
    App2 --> CH
    App3 --> CH
    
    App1 --> Redis[(Redis)]
    App2 --> Redis
    App3 --> Redis
```

### 多节点集群部署

```mermaid
graph TB
    subgraph "负载均衡层"
        LB1[Nginx 1]
        LB2[Nginx 2]
    end
    
    subgraph "应用层"
        App1[Django Node 1]
        App2[Django Node 2]
        App3[Django Node 3]
    end
    
    subgraph "数据层"
        DB1[(PostgreSQL Master)]
        DB2[(PostgreSQL Replica)]
        OS1[(OpenSearch Node 1)]
        OS2[(OpenSearch Node 2)]
        OS3[(OpenSearch Node 3)]
        CH1[(ClickHouse Node 1)]
        CH2[(ClickHouse Node 2)]
    end
    
    LB1 --> App1
    LB1 --> App2
    LB2 --> App2
    LB2 --> App3
    
    App1 --> DB1
    App2 --> DB1
    App3 --> DB2
    
    App1 --> OS1
    App2 --> OS2
    App3 --> OS3
```

## 配置管理

### 环境变量配置

#### 开发环境 (.env.dev)
```bash
# 基础配置
DJANGO_DEBUG=true
DJANGO_SECRET_KEY=dev-secret-key
DJANGO_ALLOWED_HOSTS=localhost,127.0.0.1,*.local

# 多站点配置
MULTI_SITE_ENABLED=true
DEFAULT_SITE_IDENTIFIER=localhost
SITE_HOSTNAME=localhost

# 数据库配置
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=idp_cms_dev
POSTGRES_USER=dev_user
POSTGRES_PASSWORD=dev_password

# OpenSearch 配置
OPENSEARCH_URL=http://localhost:9200
OPENSEARCH_USERNAME=admin
OPENSEARCH_PASSWORD=admin

# ClickHouse 配置
CLICKHOUSE_URL=clickhouse://default:dev_password@localhost:9000/default

# Redis 配置
REDIS_URL=redis://localhost:6379/1

# 时区配置
DJANGO_TIME_ZONE=Asia/Shanghai
```

#### 测试环境 (.env.test)
```bash
# 基础配置
DJANGO_DEBUG=false
DJANGO_SECRET_KEY=test-secret-key-change-in-production
DJANGO_ALLOWED_HOSTS=test.example.com,test-a.example.com,test-b.example.com

# 多站点配置
MULTI_SITE_ENABLED=true
DEFAULT_SITE_IDENTIFIER=test.example.com
SITE_HOSTNAME=test.example.com

# 数据库配置
POSTGRES_HOST=postgres-test
POSTGRES_PORT=5432
POSTGRES_DB=idp_cms_test
POSTGRES_USER=test_user
POSTGRES_PASSWORD=test_secure_password

# OpenSearch 配置
OPENSEARCH_URL=https://opensearch-test:9200
OPENSEARCH_USERNAME=admin
OPENSEARCH_PASSWORD=test_opensearch_password

# ClickHouse 配置
CLICKHOUSE_URL=clickhouse://default:test_password@clickhouse-test:9000/default

# Redis 配置
REDIS_URL=redis://redis-test:6379/1

# SSL配置
DJANGO_SECURE_SSL_REDIRECT=true
DJANGO_SECURE_HSTS_SECONDS=31536000
```

#### 生产环境 (.env.prod)
```bash
# 基础配置
DJANGO_DEBUG=false
DJANGO_SECRET_KEY=${SECRET_KEY_FROM_VAULT}
DJANGO_ALLOWED_HOSTS=example.com,site-a.com,site-b.com,portal.com

# 多站点配置
MULTI_SITE_ENABLED=true
DEFAULT_SITE_IDENTIFIER=example.com
SITE_HOSTNAME=example.com

# 数据库配置 (使用密钥管理)
POSTGRES_HOST=postgres-cluster.internal
POSTGRES_PORT=5432
POSTGRES_DB=idp_cms_prod
POSTGRES_USER=${DB_USER_FROM_VAULT}
POSTGRES_PASSWORD=${DB_PASSWORD_FROM_VAULT}

# OpenSearch 配置
OPENSEARCH_URL=https://opensearch-cluster.internal:9200
OPENSEARCH_USERNAME=${OS_USER_FROM_VAULT}
OPENSEARCH_PASSWORD=${OS_PASSWORD_FROM_VAULT}

# ClickHouse 配置
CLICKHOUSE_URL=clickhouse://${CH_USER}:${CH_PASSWORD}@clickhouse-cluster.internal:9000/production

# Redis 配置
REDIS_URL=redis://redis-cluster.internal:6379/1

# 安全配置
DJANGO_SECURE_SSL_REDIRECT=true
DJANGO_SECURE_HSTS_SECONDS=31536000
DJANGO_SECURE_HSTS_INCLUDE_SUBDOMAINS=true
DJANGO_SECURE_HSTS_PRELOAD=true
DJANGO_SECURE_CONTENT_TYPE_NOSNIFF=true
DJANGO_SECURE_BROWSER_XSS_FILTER=true
DJANGO_SECURE_REFERRER_POLICY=strict-origin-when-cross-origin

# 监控配置
SENTRY_DSN=${SENTRY_DSN_FROM_VAULT}
PROMETHEUS_METRICS_ENABLED=true
```

### Nginx 配置

#### 多站点反向代理配置

```nginx
# /etc/nginx/sites-available/multi-site
upstream django_backend {
    least_conn;
    server app1:8000 max_fails=3 fail_timeout=30s;
    server app2:8000 max_fails=3 fail_timeout=30s;
    server app3:8000 max_fails=3 fail_timeout=30s;
}

# 日志格式
log_format multi_site '$remote_addr - $remote_user [$time_local] '
                     '"$request" $status $body_bytes_sent '
                     '"$http_referer" "$http_user_agent" '
                     '"$http_host" $request_time';

# 站点A配置
server {
    listen 80;
    listen 443 ssl http2;
    server_name site-a.com www.site-a.com;
    
    # SSL配置
    ssl_certificate /etc/nginx/ssl/site-a.com.crt;
    ssl_certificate_key /etc/nginx/ssl/site-a.com.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;
    
    # 安全头
    add_header X-Frame-Options DENY always;
    add_header X-Content-Type-Options nosniff always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    
    # 日志
    access_log /var/log/nginx/site-a-access.log multi_site;
    error_log /var/log/nginx/site-a-error.log;
    
    # 静态文件
    location /static/ {
        alias /app/static/;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
    
    location /media/ {
        alias /app/media/;
        expires 1y;
        add_header Cache-Control "public";
    }
    
    # API请求
    location /api/ {
        proxy_pass http://django_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_set_header X-Forwarded-Host $host;
        proxy_set_header X-Forwarded-Port $server_port;
        
        # 缓存配置
        proxy_cache_bypass $http_pragma;
        proxy_cache_revalidate on;
        proxy_cache_min_uses 1;
        proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;
        proxy_cache_background_update on;
        proxy_cache_lock on;
        
        # 超时配置
        proxy_connect_timeout 30s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }
    
    # 管理后台
    location /admin/ {
        proxy_pass http://django_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # 访问控制 (可选)
        # allow 192.168.1.0/24;
        # deny all;
    }
    
    # 前端应用
    location / {
        proxy_pass http://portal_frontend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}

# 站点B配置（类似站点A）
server {
    listen 80;
    listen 443 ssl http2;
    server_name site-b.com www.site-b.com;
    
    # ... 类似配置
}

# 门户站点配置
server {
    listen 80;
    listen 443 ssl http2;
    server_name portal.com www.portal.com;
    
    # ... 类似配置
}

# HTTP到HTTPS重定向
server {
    listen 80;
    server_name site-a.com site-b.com portal.com;
    return 301 https://$server_name$request_uri;
}
```

## 自动化部署

### Docker 构建脚本

```bash
#!/bin/bash
# scripts/build.sh

set -e

VERSION=${1:-latest}
REGISTRY=${REGISTRY:-your-registry.com}

echo "🚀 构建多站点应用镜像 v${VERSION}"

# 构建后端镜像
echo "📦 构建 Django 后端..."
docker build -t ${REGISTRY}/idp-cms/authoring:${VERSION} \
  -f docker/Dockerfile.authoring .

# 构建前端镜像
echo "📦 构建 Next.js 前端..."
docker build -t ${REGISTRY}/idp-cms/portal:${VERSION} \
  -f docker/Dockerfile.portal ./portal/next

# 推送到镜像仓库
if [[ "${PUSH:-true}" == "true" ]]; then
  echo "📤 推送镜像到仓库..."
  docker push ${REGISTRY}/idp-cms/authoring:${VERSION}
  docker push ${REGISTRY}/idp-cms/portal:${VERSION}
fi

echo "✅ 构建完成!"
```

### 部署脚本

```bash
#!/bin/bash
# scripts/deploy.sh

set -e

ENVIRONMENT=${1:-staging}
VERSION=${2:-latest}

echo "🚀 部署到 ${ENVIRONMENT} 环境 (版本: ${VERSION})"

# 检查环境
case $ENVIRONMENT in
  "staging"|"production")
    ;;
  *)
    echo "❌ 无效的环境: $ENVIRONMENT"
    exit 1
    ;;
esac

# 设置环境变量
export COMPOSE_FILE="docker-compose.${ENVIRONMENT}.yml"
export IMAGE_TAG=${VERSION}

# 备份当前配置
echo "💾 备份当前配置..."
docker compose ps > "backup/services-before-${VERSION}-$(date +%Y%m%d_%H%M%S).txt"

# 拉取新镜像
echo "📥 拉取新镜像..."
docker compose pull

# 数据库迁移
echo "🗄️  执行数据库迁移..."
docker compose run --rm authoring python authoring/manage.py migrate

# 更新静态文件
echo "📄 收集静态文件..."
docker compose run --rm authoring python authoring/manage.py collectstatic --noinput

# 更新搜索索引
echo "🔍 更新搜索索引..."
docker compose run --rm authoring python authoring/manage.py setup_sites

# 滚动更新
echo "🔄 执行滚动更新..."
docker compose up -d --remove-orphans

# 健康检查
echo "🏥 健康检查..."
./scripts/health_check.sh

echo "✅ 部署完成!"
```

### 健康检查脚本

```bash
#!/bin/bash
# scripts/health_check.sh

set -e

TIMEOUT=300  # 5分钟超时
INTERVAL=10  # 10秒间隔检查

sites=("localhost" "site-a.local" "site-b.local" "portal.local")
health_check_url="/api/health"

echo "🏥 执行健康检查..."

check_service() {
    local site=$1
    local url="http://localhost:8000${health_check_url}"
    
    echo "检查 ${site}..."
    
    response=$(curl -s -w "%{http_code}" \
                   -H "Host: ${site}" \
                   -H "Accept: application/json" \
                   -o /dev/null \
                   "${url}" || echo "000")
    
    if [[ "$response" == "200" ]]; then
        echo "✅ ${site} 健康"
        return 0
    else
        echo "❌ ${site} 不健康 (HTTP ${response})"
        return 1
    fi
}

# 等待服务启动
echo "⏳ 等待服务启动..."
sleep 30

# 检查所有站点
start_time=$(date +%s)
all_healthy=false

while [[ $all_healthy == false ]]; do
    current_time=$(date +%s)
    elapsed=$((current_time - start_time))
    
    if [[ $elapsed -gt $TIMEOUT ]]; then
        echo "❌ 健康检查超时 (${TIMEOUT}秒)"
        exit 1
    fi
    
    echo "检查轮次 $((elapsed / INTERVAL + 1))..."
    
    healthy_count=0
    for site in "${sites[@]}"; do
        if check_service "$site"; then
            ((healthy_count++))
        fi
    done
    
    if [[ $healthy_count -eq ${#sites[@]} ]]; then
        all_healthy=true
        echo "🎉 所有站点健康检查通过!"
    else
        echo "⏳ 等待 ${INTERVAL} 秒后重试..."
        sleep $INTERVAL
    fi
done

# 详细的API功能测试
echo ""
echo "🧪 执行功能测试..."

for site in "${sites[@]}"; do
    echo "测试 ${site} 的 Feed API..."
    
    response=$(curl -s \
                   -H "Host: ${site}" \
                   -H "Accept: application/json" \
                   "http://localhost:8000/api/feed?size=1")
    
    # 检查响应是否包含预期字段
    if echo "$response" | jq -e '.items | length' > /dev/null 2>&1; then
        item_count=$(echo "$response" | jq '.items | length')
        site_returned=$(echo "$response" | jq -r '.debug.site')
        echo "✅ ${site}: 返回 ${item_count} 篇文章，识别站点: ${site_returned}"
    else
        echo "❌ ${site}: API响应格式错误"
        echo "响应内容: $response"
        exit 1
    fi
done

echo "🎉 所有功能测试通过!"
```

### CI/CD 配置

#### GitHub Actions

```yaml
# .github/workflows/deploy.yml
name: Multi-Site Deployment

on:
  push:
    branches:
      - main
      - staging
  pull_request:
    branches:
      - main

env:
  REGISTRY: ghcr.io
  IMAGE_BASE: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          
      opensearch:
        image: opensearchproject/opensearch:2.11.0
        env:
          discovery.type: single-node
          DISABLE_SECURITY_PLUGIN: true
        options: >-
          --health-cmd "curl -f http://localhost:9200/_cluster/health"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
        
    - name: Install dependencies
      run: |
        cd authoring
        pip install -r requirements.txt
        
    - name: Run tests
      env:
        DATABASE_URL: postgresql://postgres:test_password@localhost/test_db
        OPENSEARCH_URL: http://localhost:9200
      run: |
        cd authoring
        python manage.py test
        
    - name: Test multi-site functionality
      run: |
        cd authoring
        python manage.py check
        python manage.py setup_sites --dry-run

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: |
          ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/authoring
          ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/portal
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha
          
    - name: Build and push Django image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./docker/Dockerfile.authoring
        push: true
        tags: ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/authoring:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        
    - name: Build and push Next.js image
      uses: docker/build-push-action@v5
      with:
        context: ./portal/next
        file: ./docker/Dockerfile.portal
        push: true
        tags: ${{ env.REGISTRY }}/${{ env.IMAGE_BASE }}/portal:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy-staging:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/staging'
    environment: staging
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Deploy to staging
      run: |
        echo "🚀 部署到测试环境..."
        # 实际部署逻辑
        ./scripts/deploy.sh staging ${{ github.sha }}
        
  deploy-production:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Deploy to production
      run: |
        echo "🚀 部署到生产环境..."
        # 实际部署逻辑
        ./scripts/deploy.sh production ${{ github.sha }}
```

## 监控告警

### Prometheus 监控配置

```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "rules/*.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  # Django 应用监控
  - job_name: 'django-multi-site'
    static_configs:
      - targets: ['app1:8000', 'app2:8000', 'app3:8000']
    metrics_path: '/metrics'
    scrape_interval: 30s
    
  # OpenSearch 监控
  - job_name: 'opensearch'
    static_configs:
      - targets: ['opensearch:9200']
    metrics_path: '/_prometheus/metrics'
    
  # ClickHouse 监控
  - job_name: 'clickhouse'
    static_configs:
      - targets: ['clickhouse:9363']
      
  # Redis 监控
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
      
  # Nginx 监控
  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx-exporter:9113']
```

### 告警规则

```yaml
# monitoring/rules/multi-site.yml
groups:
- name: multi-site-alerts
  rules:
  
  # API 响应时间告警
  - alert: HighAPIResponseTime
    expr: histogram_quantile(0.95, rate(django_request_duration_seconds_bucket[5m])) > 2
    for: 5m
    labels:
      severity: warning
      service: django
    annotations:
      summary: "API响应时间过高"
      description: "{{ $labels.site }} 站点的95%请求响应时间超过2秒"
      
  # API 错误率告警
  - alert: HighAPIErrorRate
    expr: rate(django_request_exceptions_total[5m]) / rate(django_requests_total[5m]) > 0.05
    for: 5m
    labels:
      severity: critical
      service: django
    annotations:
      summary: "API错误率过高"
      description: "{{ $labels.site }} 站点的API错误率超过5%"
      
  # OpenSearch 索引健康告警
  - alert: OpenSearchIndexDown
    expr: elasticsearch_cluster_health_status{color!="green"} > 0
    for: 2m
    labels:
      severity: critical
      service: opensearch
    annotations:
      summary: "OpenSearch索引状态异常"
      description: "OpenSearch集群状态为 {{ $labels.color }}"
      
  # 站点特定的流量告警
  - alert: LowSiteTraffic
    expr: rate(django_requests_total[10m]) < 1
    for: 10m
    labels:
      severity: warning
      service: django
    annotations:
      summary: "站点流量异常低"
      description: "{{ $labels.site }} 站点在过去10分钟内请求量低于1 req/sec"
      
  # 内存使用告警
  - alert: HighMemoryUsage
    expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
    for: 5m
    labels:
      severity: warning
      service: system
    annotations:
      summary: "内存使用率过高"
      description: "服务器内存使用率超过85%: {{ $value }}%"
      
  # 磁盘空间告警
  - alert: LowDiskSpace
    expr: (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 > 80
    for: 5m
    labels:
      severity: warning
      service: system
    annotations:
      summary: "磁盘空间不足"
      description: "{{ $labels.mountpoint }} 磁盘使用率超过80%: {{ $value }}%"
```

### Grafana 仪表板

```json
{
  "dashboard": {
    "title": "多站点监控仪表板",
    "panels": [
      {
        "title": "站点QPS",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(django_requests_total[1m])",
            "legendFormat": "{{ site }} - {{ method }}"
          }
        ]
      },
      {
        "title": "站点响应时间",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(django_request_duration_seconds_bucket[5m]))",
            "legendFormat": "{{ site }} - P50"
          },
          {
            "expr": "histogram_quantile(0.95, rate(django_request_duration_seconds_bucket[5m]))",
            "legendFormat": "{{ site }} - P95"
          }
        ]
      },
      {
        "title": "站点错误率",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(django_request_exceptions_total[5m]) / rate(django_requests_total[5m]) * 100",
            "legendFormat": "{{ site }} 错误率 (%)"
          }
        ]
      },
      {
        "title": "OpenSearch 索引状态",
        "type": "table",
        "targets": [
          {
            "expr": "elasticsearch_indices_docs{index=~\"news_.*_articles.*\"}",
            "format": "table"
          }
        ]
      }
    ]
  }
}
```

## 备份恢复

### 数据备份策略

#### PostgreSQL 备份

```bash
#!/bin/bash
# scripts/backup_postgres.sh

set -e

BACKUP_DIR="/backups/postgres"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30

echo "🗄️  开始 PostgreSQL 备份..."

# 创建备份目录
mkdir -p $BACKUP_DIR

# 全量备份
docker exec postgres pg_dumpall -U postgres | \
  gzip > "$BACKUP_DIR/full_backup_$DATE.sql.gz"

# 按站点备份（如果需要）
sites=("localhost" "site_a_local" "site_b_local" "portal_local")
for site in "${sites[@]}"; do
  echo "备份站点数据: $site"
  docker exec postgres pg_dump -U postgres idp_cms_prod \
    --table="*$site*" | \
    gzip > "$BACKUP_DIR/site_${site}_$DATE.sql.gz"
done

# 清理旧备份
find $BACKUP_DIR -name "*.sql.gz" -mtime +$RETENTION_DAYS -delete

echo "✅ PostgreSQL 备份完成"
```

#### OpenSearch 备份

```bash
#!/bin/bash
# scripts/backup_opensearch.sh

set -e

BACKUP_DIR="/backups/opensearch"
DATE=$(date +%Y%m%d_%H%M%S)
OS_URL="http://localhost:9200"
OS_USER="admin"
OS_PASS="admin"

echo "🔍 开始 OpenSearch 备份..."

# 创建备份目录
mkdir -p $BACKUP_DIR

# 获取所有多站点索引
indices=$(curl -s -u $OS_USER:$OS_PASS "$OS_URL/_cat/indices?h=index" | \
          grep "news_.*_articles" | tr '\n' ',')

if [[ -n "$indices" ]]; then
  # 创建快照仓库（如果不存在）
  curl -s -u $OS_USER:$OS_PASS -X PUT "$OS_URL/_snapshot/backup_repo" \
    -H "Content-Type: application/json" \
    -d '{
      "type": "fs",
      "settings": {
        "location": "/backup",
        "compress": true
      }
    }'
  
  # 创建快照
  snapshot_name="multi_site_backup_$DATE"
  curl -s -u $OS_USER:$OS_PASS -X PUT \
    "$OS_URL/_snapshot/backup_repo/$snapshot_name" \
    -H "Content-Type: application/json" \
    -d "{
      \"indices\": \"${indices%,}\",
      \"include_global_state\": false
    }"
  
  echo "✅ OpenSearch 快照创建完成: $snapshot_name"
else
  echo "⚠️  未找到需要备份的索引"
fi
```

### 数据恢复流程

#### 灾难恢复脚本

```bash
#!/bin/bash
# scripts/disaster_recovery.sh

set -e

BACKUP_DATE=${1:-latest}
RESTORE_SITE=${2:-all}

echo "🚨 开始灾难恢复 (备份日期: $BACKUP_DATE, 站点: $RESTORE_SITE)"

# 停止应用服务
echo "⏸️  停止应用服务..."
docker compose stop authoring portal

# 恢复 PostgreSQL
if [[ "$RESTORE_SITE" == "all" ]]; then
  echo "🗄️  恢复 PostgreSQL 全量数据..."
  if [[ "$BACKUP_DATE" == "latest" ]]; then
    backup_file=$(ls -t /backups/postgres/full_backup_*.sql.gz | head -1)
  else
    backup_file="/backups/postgres/full_backup_$BACKUP_DATE.sql.gz"
  fi
  
  if [[ -f "$backup_file" ]]; then
    gunzip -c "$backup_file" | docker exec -i postgres psql -U postgres
    echo "✅ PostgreSQL 恢复完成"
  else
    echo "❌ 备份文件不存在: $backup_file"
    exit 1
  fi
else
  echo "🗄️  恢复站点数据: $RESTORE_SITE"
  # 站点特定恢复逻辑
fi

# 恢复 OpenSearch
echo "🔍 恢复 OpenSearch 数据..."
# OpenSearch 恢复逻辑

# 重新启动服务
echo "🚀 重新启动服务..."
docker compose up -d

# 健康检查
echo "🏥 执行健康检查..."
./scripts/health_check.sh

echo "✅ 灾难恢复完成"
```

## 性能优化

### 数据库优化

#### PostgreSQL 配置优化

```sql
-- postgresql.conf 优化配置
shared_buffers = 4GB                    -- 25% of total RAM
effective_cache_size = 12GB              -- 75% of total RAM
maintenance_work_mem = 1GB
checkpoint_segments = 32
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 100
random_page_cost = 1.1                  -- SSD优化
effective_io_concurrency = 200          -- SSD并发优化

-- 站点特定索引优化
CREATE INDEX CONCURRENTLY idx_articles_site_publish_time 
  ON articles (site, publish_time DESC);
  
CREATE INDEX CONCURRENTLY idx_articles_site_topic_score 
  ON articles (site, topic, quality_score DESC);
  
-- 分区表优化（按站点分区）
CREATE TABLE articles_partitioned (
  id SERIAL,
  site VARCHAR(100),
  title TEXT,
  content TEXT,
  publish_time TIMESTAMP,
  -- 其他字段...
) PARTITION BY LIST (site);

-- 为每个站点创建分区
CREATE TABLE articles_localhost PARTITION OF articles_partitioned
  FOR VALUES IN ('localhost');
  
CREATE TABLE articles_site_a PARTITION OF articles_partitioned
  FOR VALUES IN ('site-a.local');
```

### OpenSearch 优化

#### 索引配置优化

```json
{
  "settings": {
    "number_of_shards": 2,
    "number_of_replicas": 1,
    "refresh_interval": "30s",
    "index": {
      "codec": "best_compression",
      "max_result_window": 10000,
      "mapping": {
        "total_fields": {
          "limit": 2000
        }
      },
      "search": {
        "slowlog": {
          "threshold": {
            "query": {
              "warn": "10s",
              "info": "5s"
            }
          }
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "site": {
        "type": "keyword"
      },
      "title": {
        "type": "text",
        "analyzer": "ik_max_word",
        "search_analyzer": "ik_smart"
      },
      "body": {
        "type": "text",
        "analyzer": "ik_max_word"
      },
      "publish_time": {
        "type": "date",
        "format": "strict_date_optional_time||epoch_millis"
      },
      "quality_score": {
        "type": "float"
      },
      "ctr_1h": {
        "type": "float"
      }
    }
  }
}
```

### 应用层优化

#### Django 配置优化

```python
# authoring/authoring/settings/production.py

# 数据库连接池优化
DATABASES['default'].update({
    'CONN_MAX_AGE': 600,
    'OPTIONS': {
        'MAX_CONNS': 20,
        'MIN_CONNS': 5,
    }
})

# 缓存配置
CACHES = {
    'default': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': 'redis://redis-cluster:6379/1',
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.DefaultClient',
            'CONNECTION_POOL_KWARGS': {
                'max_connections': 50,
                'retry_on_timeout': True,
            },
            'COMPRESSOR': 'django_redis.compressors.zlib.ZlibCompressor',
            'SERIALIZER': 'django_redis.serializers.json.JSONSerializer',
        },
        'TIMEOUT': 300,
        'KEY_PREFIX': 'multisite',
        'VERSION': 1,
    }
}

# 会话配置
SESSION_ENGINE = 'django.contrib.sessions.backends.cache'
SESSION_CACHE_ALIAS = 'default'
SESSION_COOKIE_AGE = 86400  # 24小时

# 站点特定缓存
SITE_CACHE_TIMEOUT = {
    'localhost': 300,      # 5分钟
    'site-a.local': 600,   # 10分钟
    'site-b.local': 600,   # 10分钟
    'portal.local': 1800,  # 30分钟
}
```

#### API 缓存策略

```python
# apps/api/cache.py
from django.core.cache import cache
from django.utils.encoding import force_str
import hashlib

class SiteBasedCacheMiddleware:
    def __init__(self, get_response):
        self.get_response = get_response
    
    def __call__(self, request):
        # 生成站点特定的缓存键
        site = request.get_host()
        cache_key = self.make_cache_key(request, site)
        
        # 检查缓存
        response = cache.get(cache_key)
        if response is not None:
            return response
        
        # 处理请求
        response = self.get_response(request)
        
        # 缓存响应（仅对GET请求）
        if request.method == 'GET' and response.status_code == 200:
            timeout = SITE_CACHE_TIMEOUT.get(site, 300)
            cache.set(cache_key, response, timeout)
        
        return response
    
    def make_cache_key(self, request, site):
        path = request.get_full_path()
        key_parts = [site, path]
        key = ':'.join(key_parts)
        return hashlib.md5(force_str(key).encode()).hexdigest()
```

## 故障处理

### 常见故障场景

#### 1. 站点无法访问

**故障现象**: 特定站点返回502/503错误

**排查步骤**:
```bash
# 1. 检查服务状态
docker compose ps

# 2. 检查容器日志
docker compose logs -f authoring

# 3. 检查站点配置
curl -I -H "Host: problem-site.com" http://localhost:8000/api/health

# 4. 检查负载均衡配置
nginx -t
systemctl status nginx

# 5. 检查数据库连接
docker compose exec authoring python authoring/manage.py dbshell
```

**解决方案**:
```bash
# 重启特定服务
docker compose restart authoring

# 重新加载nginx配置
nginx -s reload

# 如果需要，回滚到上一个版本
./scripts/rollback.sh
```

#### 2. OpenSearch 索引异常

**故障现象**: 搜索功能异常，返回空结果

**排查步骤**:
```bash
# 1. 检查索引状态
curl -u admin:password "http://localhost:9200/_cat/indices?v"

# 2. 检查集群健康
curl -u admin:password "http://localhost:9200/_cluster/health?pretty"

# 3. 检查索引映射
curl -u admin:password "http://localhost:9200/news_*/_mapping"

# 4. 测试查询
curl -u admin:password -X GET "http://localhost:9200/news_localhost_articles/_search?q=*"
```

**解决方案**:
```bash
# 重建异常索引
docker compose exec authoring python authoring/manage.py setup_sites --create-indices

# 如果需要，从备份恢复
./scripts/restore_opensearch.sh latest
```

#### 3. 数据库性能问题

**故障现象**: API响应缓慢，数据库CPU使用率高

**排查步骤**:
```sql
-- 检查慢查询
SELECT query, mean_exec_time, calls
FROM pg_stat_statements
WHERE mean_exec_time > 1000
ORDER BY mean_exec_time DESC;

-- 检查锁等待
SELECT * FROM pg_stat_activity 
WHERE wait_event IS NOT NULL;

-- 检查连接数
SELECT count(*) FROM pg_stat_activity;
```

**解决方案**:
```bash
# 重启数据库连接池
docker compose restart authoring

# 分析并优化慢查询
# 添加必要的索引
# 调整数据库配置参数
```

### 故障自动恢复

#### 自动重启脚本

```bash
#!/bin/bash
# scripts/auto_recovery.sh

set -e

HEALTH_CHECK_URL="http://localhost:8000/api/health"
MAX_FAILURES=3
FAILURE_COUNT=0

while true; do
    sites=("localhost" "site-a.local" "site-b.local" "portal.local")
    
    for site in "${sites[@]}"; do
        echo "检查站点: $site"
        
        if ! curl -f -s -H "Host: $site" "$HEALTH_CHECK_URL" > /dev/null; then
            echo "❌ 站点 $site 健康检查失败"
            ((FAILURE_COUNT++))
            
            if [[ $FAILURE_COUNT -ge $MAX_FAILURES ]]; then
                echo "🚨 触发自动恢复..."
                
                # 尝试重启服务
                docker compose restart authoring
                sleep 30
                
                # 重新检查
                if curl -f -s -H "Host: $site" "$HEALTH_CHECK_URL" > /dev/null; then
                    echo "✅ 自动恢复成功"
                    FAILURE_COUNT=0
                else
                    echo "❌ 自动恢复失败，发送告警"
                    # 发送告警通知
                    ./scripts/send_alert.sh "自动恢复失败: $site"
                fi
            fi
        else
            echo "✅ 站点 $site 正常"
            FAILURE_COUNT=0
        fi
    done
    
    sleep 60  # 每分钟检查一次
done
```

## 扩容方案

### 水平扩容

#### 应用层扩容

```bash
# 增加Django应用实例
docker compose up -d --scale authoring=5

# 更新负载均衡配置
# 添加新的upstream服务器到nginx配置
```

#### 数据库扩容

```yaml
# 读写分离配置
version: '3.8'
services:
  postgres-master:
    image: postgres:15
    environment:
      POSTGRES_REPLICATION_USER: replicator
      POSTGRES_REPLICATION_PASSWORD: repl_password
    
  postgres-replica1:
    image: postgres:15
    environment:
      POSTGRES_MASTER_SERVICE: postgres-master
      POSTGRES_REPLICATION_USER: replicator
      POSTGRES_REPLICATION_PASSWORD: repl_password
    
  postgres-replica2:
    image: postgres:15
    environment:
      POSTGRES_MASTER_SERVICE: postgres-master
      POSTGRES_REPLICATION_USER: replicator
      POSTGRES_REPLICATION_PASSWORD: repl_password
```

#### OpenSearch 集群扩容

```yaml
# OpenSearch 集群配置
version: '3.8'
services:
  opensearch-master:
    image: opensearchproject/opensearch:2.11.0
    environment:
      - cluster.name=multi-site-cluster
      - node.name=opensearch-master
      - node.roles=master,data,ingest
      - discovery.seed_hosts=opensearch-data1,opensearch-data2
      - cluster.initial_master_nodes=opensearch-master
      
  opensearch-data1:
    image: opensearchproject/opensearch:2.11.0
    environment:
      - cluster.name=multi-site-cluster
      - node.name=opensearch-data1
      - node.roles=data,ingest
      - discovery.seed_hosts=opensearch-master,opensearch-data2
      
  opensearch-data2:
    image: opensearchproject/opensearch:2.11.0
    environment:
      - cluster.name=multi-site-cluster
      - node.name=opensearch-data2
      - node.roles=data,ingest
      - discovery.seed_hosts=opensearch-master,opensearch-data1
```

### 自动扩容

#### Kubernetes 部署

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: multi-site-authoring
spec:
  replicas: 3
  selector:
    matchLabels:
      app: authoring
  template:
    metadata:
      labels:
        app: authoring
    spec:
      containers:
      - name: authoring
        image: idp-cms/authoring:latest
        ports:
        - containerPort: 8000
        env:
        - name: MULTI_SITE_ENABLED
          value: "true"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
        livenessProbe:
          httpGet:
            path: /api/health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /api/health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: authoring-service
spec:
  selector:
    app: authoring
  ports:
  - port: 80
    targetPort: 8000
  type: ClusterIP

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: authoring-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: multi-site-authoring
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

---

## 总结

多站点部署运维涵盖了从环境准备到自动化扩容的完整生命周期：

✅ **全面的环境配置** - 开发、测试、生产环境的标准化配置  
✅ **自动化部署流程** - CI/CD pipeline 和脚本化部署  
✅ **完善的监控体系** - Prometheus + Grafana + 告警规则  
✅ **可靠的备份恢复** - 数据库和搜索引擎的备份策略  
✅ **性能优化方案** - 应用、数据库、搜索引擎的优化配置  
✅ **故障处理预案** - 常见故障的排查和自动恢复机制  
✅ **弹性扩容能力** - 支持水平和垂直扩容的架构设计  

这套运维体系为多站点架构提供了企业级的可靠性和可扩展性保障。
